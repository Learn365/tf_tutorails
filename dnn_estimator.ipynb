{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# https://docs.python.org/3/library/urllib.request.html#urllib.request.urlopen\n",
    "import urllib.request\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data sets\n",
    "IRIS_TRAINING=\"./IRIS_data/iris_training.csv\"\n",
    "IRIS_TRAINING_URL=\"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "IRIS_TEST=\"./IRIS_data/iris_test.csv\"\n",
    "IRIS_TEST_URL=\"http://download.tensorflow.org/data/iris_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # if the training and test sets aren't stored locally, download them.\n",
    "    if not os.path.exists(IRIS_TRAINING):\n",
    "        raw = urllib.request.urlopen(IRIS_TRAINING_URL).read()\n",
    "        with open(IRIS_TRAINING, \"wb\") as f:\n",
    "            f.write(raw)\n",
    "\n",
    "    if not os.path.exists(IRIS_TEST):\n",
    "        raw = urllib.request.urlopen(IRIS_TEST_URL).read()\n",
    "        with open(IRIS_TEST, \"wb\") as f:\n",
    "            f.write(raw)\n",
    "\n",
    "    # Load datasets\n",
    "    training_sets = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "        filename=IRIS_TRAINING,\n",
    "        target_dtype=np.int,\n",
    "        features_dtype=np.float32\n",
    "    )\n",
    "    test_sets = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "        filename=IRIS_TEST,\n",
    "        target_dtype=np.int,\n",
    "        features_dtype=np.float32\n",
    "    )\n",
    "\n",
    "    # Specify that all features have real-value data\n",
    "    feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[4])]\n",
    "\n",
    "    # Build 3 layer DNN with 10,20,10 units respectively\n",
    "    classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,\n",
    "                                            hidden_units=[10, 20, 10],\n",
    "                                            n_classes=3,\n",
    "                                            model_dir=\"./models/iris_model\")\n",
    "    # Define the training inputs\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": np.array(training_sets.data)},\n",
    "        y=np.array(training_sets.target),\n",
    "        num_epochs=None,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # Train model.\n",
    "    classifier.train(input_fn=train_input_fn, steps=2000)\n",
    "\n",
    "    # Define the test inputs\n",
    "    test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": np.array(test_sets.data)},\n",
    "        y=np.array(test_sets.target),\n",
    "        num_epochs=1,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Evaluate accuracy.\n",
    "    accuracy=classifier.evaluate(input_fn=test_input_fn)\n",
    "    print(\"accuracy: \",accuracy)\n",
    "    \n",
    "    accuracy_score = accuracy[\"accuracy\"]\n",
    "\n",
    "    print(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score))\n",
    "\n",
    "    # Classify two new flower samples.\n",
    "    new_samples = np.array(\n",
    "        [[6.4, 3.2, 4.5, 1.5],\n",
    "         [5.8, 3.1, 5.0, 1.7]], dtype=np.float32\n",
    "    )\n",
    "\n",
    "    predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": new_samples},\n",
    "        num_epochs=1,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    predictions = list(classifier.predict(input_fn=predict_input_fn))\n",
    "    predicted_classes = [(p[\"classes\"])[0] for p in predictions]\n",
    "\n",
    "    \n",
    "    print(\n",
    "        \"New Samples, Class Predictions: {}\\n\"\n",
    "            .format(predicted_classes)\n",
    "    )\n",
    "    \n",
    "    for p_class in predicted_classes:\n",
    "        print(p_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_tf_random_seed': 1, '_keep_checkpoint_every_n_hours': 10000, '_keep_checkpoint_max': 5, '_session_config': None, '_save_checkpoints_secs': 600, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_log_step_count_steps': 100, '_model_dir': './models/iris_model'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./models/iris_model/model.ckpt-14000\n",
      "INFO:tensorflow:Saving checkpoints for 14001 into ./models/iris_model/model.ckpt.\n",
      "INFO:tensorflow:step = 14001, loss = 8.98668\n",
      "INFO:tensorflow:global_step/sec: 692.342\n",
      "INFO:tensorflow:step = 14101, loss = 4.14046 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 668.799\n",
      "INFO:tensorflow:step = 14201, loss = 4.43707 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 683.46\n",
      "INFO:tensorflow:step = 14301, loss = 1.28895 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 665.759\n",
      "INFO:tensorflow:step = 14401, loss = 3.70411 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.607\n",
      "INFO:tensorflow:step = 14501, loss = 3.19839 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.59\n",
      "INFO:tensorflow:step = 14601, loss = 3.21715 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 672.018\n",
      "INFO:tensorflow:step = 14701, loss = 1.3706 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.219\n",
      "INFO:tensorflow:step = 14801, loss = 2.41552 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 619.426\n",
      "INFO:tensorflow:step = 14901, loss = 4.62691 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 631.128\n",
      "INFO:tensorflow:step = 15001, loss = 5.02914 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 626.402\n",
      "INFO:tensorflow:step = 15101, loss = 2.28349 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.193\n",
      "INFO:tensorflow:step = 15201, loss = 3.03034 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 569.677\n",
      "INFO:tensorflow:step = 15301, loss = 3.46596 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.477\n",
      "INFO:tensorflow:step = 15401, loss = 3.15453 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 639.913\n",
      "INFO:tensorflow:step = 15501, loss = 1.38431 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.982\n",
      "INFO:tensorflow:step = 15601, loss = 2.62811 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.095\n",
      "INFO:tensorflow:step = 15701, loss = 3.51187 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 627.675\n",
      "INFO:tensorflow:step = 15801, loss = 4.0761 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 657.548\n",
      "INFO:tensorflow:step = 15901, loss = 2.30825 (0.152 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into ./models/iris_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.73798.\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-10-05:20:31\n",
      "INFO:tensorflow:Restoring parameters from ./models/iris_model/model.ckpt-16000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-10-05:20:31\n",
      "INFO:tensorflow:Saving dict for global step 16000: accuracy = 0.966667, average_loss = 0.157668, global_step = 16000, loss = 4.73004\n",
      "accuracy:  {'average_loss': 0.15766802, 'accuracy': 0.96666664, 'loss': 4.7300406, 'global_step': 16000}\n",
      "\n",
      "Test Accuracy: 0.966667\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./models/iris_model/model.ckpt-16000\n",
      "New Samples, Class Predictions: [b'1', b'1']\n",
      "\n",
      "b'1'\n",
      "b'1'\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
